{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import inspect\n",
    "\n",
    "# SPCA libraries\n",
    "from SPCA import helpers, astro_models, make_plots, make_plots_custom, detec_models, bliss, freeze\n",
    "from SPCA import Decorrelation_helper as dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter in parameters that will define how the rest of the code will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet = '55cnc_Nobug'\n",
    "channel = 'ch2'\n",
    "mode = 'BLISS_v1,psfw'\n",
    "rootpath = '/Users/samsonmercier/Desktop/Research'\n",
    "\n",
    "# parameters you do not wish to fit\n",
    "dparams_input = ['q1', 'q2', 'inc', 'ecosw', 'esinw', 'gpLx', 'gpLy', 't0', 'per', 'a']\n",
    "\n",
    "# parameters you want to place a gaussian prior on\n",
    "gparams = ['A', 'B']\n",
    "\n",
    "# parameters you want to place a uniform prior on\n",
    "uparams = ['rp', 'fp', 'sigF']\n",
    "uparams_limits = [[0,1], [0,1], [0,1]]\n",
    "\n",
    "binnedPhotometry = True                  # Whether or not to use the binned photometry\n",
    "oldPhotometry = False                    # Whether photometry was computed before May 1, 2020 when flux conversion was patched\n",
    "ncpu = 1                                 # The number of cpu threads to be used when running MCMC\n",
    "runMCMC = True                           # whether to run MCMC or just load-in past results\n",
    "nIterScipy = 10                          # Number of iterative scipy runs used to locate best-fit before starting MCMCs\n",
    "nBurnInSteps2 = 7.5e5                    # number of steps to use for the second mcmc burn-in\n",
    "nProductionSteps = 1.5e5                 # number of steps to use with mcmc production run\n",
    "usebestfit = True                        # used best-fit instead of median of chain\n",
    "secondOrderOffset = True                 # should you use the second order sinusoid terms when calculating offset\n",
    "bestfitNbin = 50                         # the number of binned values to overplot on the bestfit 4-panel figure (use None if you don't want these overplotted)\n",
    "nFrames  = 640                            # number of frames per binned data point\n",
    "initializeWithOld = False                # initial with previous mcmc results using the same method\n",
    "pldIgnoreFrames = True                   # Whether or not to use the PLD photometry that ignored bad frames\n",
    "pldAddStack = False                      # Whether or not to use the PLD photometry that used background correction stacks\n",
    "debug = False                            # True if user wants details about the lambda functions created\n",
    "\n",
    "# Adding companion dilution correction factor for CoRoT-2b, WASP-12b, and WASP-103b\n",
    "if planet=='CoRoT-2b':\n",
    "    compFactor = 1+0.2046\n",
    "elif planet=='WASP-12b':\n",
    "    compFactor = 1+0.09976\n",
    "elif planet=='WASP-12b_old':\n",
    "    compFactor = 1+0.09085\n",
    "elif planet=='WASP-103b':\n",
    "    compFactor = 1+0.1234\n",
    "else:\n",
    "    compFactor = 1\n",
    "\n",
    "# non-zero if you want to remove some initial data points\n",
    "cut_tmp = 0\n",
    "\n",
    "foldername = rootpath + '/55cnc_Nobug/4umExactCircular2_2_movingCentroid/'\n",
    "foldername_psf = rootpath + '/55cnc_Nobug/4umExactCircular2_2_movingCentroid/'\n",
    "filename = 'ch2_datacube_binned_AORs4807.dat'\n",
    "filename_full = 'ch2_datacube_full_AORs4807.dat'\n",
    "savepath = foldername + mode + '/'\n",
    "#path_params = \n",
    "AOR_snip = []\n",
    "aors = []\n",
    "breaks = []\n",
    "ignoreFrames = []\n",
    "cutFirstAOR = []\n",
    "cut=cut_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below can be run without interfering with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rootpath[-1]!='/':\n",
    "    rootpath += '/'\n",
    "if not binnedPhotometry:\n",
    "    nFrames = 1\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Figure out where data is located\n",
    "if 'pldaper' in mode.lower():\n",
    "    # Get separately aperture data for when running PLDAper, and decide if ignoreFrame from aperture photometry\n",
    "    foldername_aper, ignoreFrames = np.array(dh.findPhotometry(rootpath, planet, channel, '_v1'))[[0,-1]]\n",
    "    if len(ignoreFrames)==0:\n",
    "        pldIgnoreFrames = False\n",
    "    else:\n",
    "        pldIgnoreFrames = True\n",
    "    foldername_psf = ''\n",
    "else:\n",
    "    foldername_aper = ''\n",
    "\n",
    "if 'psfx' in mode.lower():\n",
    "    foldername_psf = dh.findPhotometry(rootpath, planet, channel, 'PSFX')[0]\n",
    "else:\n",
    "    foldername_psf = ''\n",
    "\n",
    "(foldername, filename, filename_full, savepath,\n",
    "path_params, AOR_snip, aors, breaks, ignoreFrames) = dh.findPhotometry(rootpath, planet, channel,\n",
    "                                                                       mode, pldIgnoreFrames, pldAddStack)\n",
    "\n",
    "with open(rootpath+planet+'/analysis/'+channel+'/cutFirstAOR.txt', 'r') as file:\n",
    "    cutFirstAOR = file.readline().strip()=='True'\n",
    "\n",
    "# For datasets where the first AOR is peak-up data\n",
    "\n",
    "if cutFirstAOR:\n",
    "    rawfiles = np.sort(os.listdir(rootpath+planet+'/data/'+channel+'/'+aors[0]+'/'+channel+'/bcd/'))\n",
    "    rawfiles  = [rawfile for rawfile in rawfiles if '_bcd.fits' in rawfile]\n",
    "    cut = cut_tmp+len(rawfiles)\n",
    "else:\n",
    "    cut = cut_tmp\n",
    "'''\n",
    "# loading full data set for BIC calculation afterwards\n",
    "if 'pld' in mode.lower():\n",
    "    # get data from unbinned photometry for chi2 on unbinned data calculation later\n",
    "    Pnorm_full, flux_full, time_full = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                             foldername_aper=foldername_aper,\n",
    "                                                             cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    if binnedPhotometry:\n",
    "        Pnorm_0, flux0, time0 = helpers.get_data(foldername, filename, mode,\n",
    "                                                 foldername_aper=foldername_aper)\n",
    "        Pnorm, flux, time = helpers.get_data(foldername, filename, mode,\n",
    "                                             foldername_aper=foldername_aper, cut=cut)\n",
    "    else:\n",
    "        Pnorm, flux, time = Pnorm_full, flux_full, time_full\n",
    "        Pnorm0, flux0, time0 = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                     foldername_aper=foldername_aper,\n",
    "                                                     nFrames=nFrames, ignore=ignoreFrames)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm_full.shape[0]-1))\n",
    "    pca.fit(Pnorm_full.T)\n",
    "    Pnorm_full = pca.transform(Pnorm_full.T).T\n",
    "    Pnorm_full = np.append(np.ones_like(Pnorm_full[:1]), Pnorm_full, axis=0)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm.shape[0]-1))\n",
    "    pca.fit(Pnorm.T)\n",
    "    Pnorm = pca.transform(Pnorm.T).T\n",
    "    Pnorm = np.append(np.ones_like(Pnorm[:1]), Pnorm, axis=0)\n",
    "    \n",
    "    if not oldPhotometry:\n",
    "        if 'pldaper' in mode.lower():\n",
    "            path_temp = foldername_aper\n",
    "        else:\n",
    "            path_temp = foldername\n",
    "        if binnedPhotometry:\n",
    "            path_temp += filename\n",
    "        else:\n",
    "            path_temp += filename_full\n",
    "        sigF_photon_ppm = dh.get_photon_limit(path_temp, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    # FIX: Add an initial PLD plot\n",
    "else:\n",
    "    # get data from photometry\n",
    "    (flux_full, time_full, xdata_full, ydata_full,\n",
    "     psfxw_full, psfyw_full) = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                     foldername_psf=foldername_psf,\n",
    "                                                     cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    if binnedPhotometry:\n",
    "        flux0, time0, xdata0, ydata0, psfxw0, psfyw0 = helpers.get_data(foldername, filename, mode,\n",
    "                                                                          foldername_psf=foldername_psf)\n",
    "        flux, time, xdata, ydata, psfxw, psfyw = helpers.get_data(foldername, filename, mode,\n",
    "                                                                    foldername_psf=foldername_psf, cut=cut)\n",
    "        \n",
    "        if not oldPhotometry:\n",
    "            sigF_photon_ppm = dh.get_photon_limit(foldername+filename, mode, nFrames, ignoreFrames)\n",
    "    else:\n",
    "        flux, time, xdata, ydata, psfxw, psfyw = (flux_full, time_full, xdata_full, ydata_full,\n",
    "                                                  psfxw_full, psfyw_full)\n",
    "        flux0, time0, xdata0, ydata0, psfxw0, psfyw0 = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                                             foldername_psf=foldername_psf,\n",
    "                                                                             cut=cut, nFrames=nFrames,\n",
    "                                                                             ignore=ignoreFrames)\n",
    "        \n",
    "        if not oldPhotometry:\n",
    "            sigF_photon_ppm = dh.get_photon_limit(foldername+filename_full, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    ## FIX: peritime doesn't get made\n",
    "    if True:#'ecosw' in dparams_input and 'esinw' in dparams_input:\n",
    "        # make photometry plots\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   showPlot=True)\n",
    "    else:\n",
    "        # plot raw data\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   peritime, showPlot=True)\n",
    "\n",
    "# Calculate the photon noise limit\n",
    "if oldPhotometry:\n",
    "    # Fix the old, unhelpful units to electrons to compute photon noise limit\n",
    "    if binnedPhotometry:\n",
    "        sigF_photon_ppm = dh.get_photon_limit_oldData(rootpath, foldername+filename_full, foldername_aper+filename_full,\n",
    "                                                      planet, channel, mode, aors, nFrames, ignoreFrames)\n",
    "    else:\n",
    "        sigF_photon_ppm = dh.get_photon_limit_oldData(rootpath, foldername+filename, foldername_aper+filename,\n",
    "                                                      planet, channel, mode, aors, nFrames, ignoreFrames)\n",
    "        \n",
    "sigF_photon_ppm *= compFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load archival/custom data and prepare some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the most recent exoplanet archive data, and select the best constrained value for each parameter\n",
    "'''dh.downloadExoplanetArchive()\n",
    "if planet!='WASP-18b':\n",
    "    p0_obj = dh.loadArchivalData(rootpath, planet, channel)'''\n",
    "\n",
    "## If you would rather load your own data (e.g. your planet isn't in the exoplanet archive),\n",
    "## you can use the function below. The error parameters are optional inputs, but are required if you want\n",
    "## to put a prior on a parameter.\n",
    "if planet=='WASP-18b':\n",
    "    # The combination of parameters loaded for WASP-18b are not consistent with each other\n",
    "    p0_obj = dh.loadCustomData(rootpath, planet, channel, 0.09716, 3.562, 0.9414526, 2458375.169883,\n",
    "                               84.88, 0.0091, 269, 6431, 4.47, 0.11,\n",
    "                               0.00014, 0.022, 0.000026, 0.0000016, 0.33, 0.00200, 3, 48)\n",
    "else:\n",
    "    p0_obj = dh.loadCustomData(rootpath, planet, channel, 0.0182, 3.52, 0.7365474, 2457063.2096, 83.59, 0.05, 86.00, 5172, 4.43, 0.35,\n",
    "                              0.0002, 0.01, 0.0005, 0.0000014, 0.46, 0.03, 32.1, 18)\n",
    "# p0_obj = loadCustomData(rootpath, planet, channel, rp, a, per, t0, inc, e, argp, Tstar, logg, feh,\n",
    "#                         rp_err, a_err, t0_err, per_err, inc_err, e_err, argp_err, Tstar_err)\n",
    "\n",
    "# if you want to use the best fit params from a previous MCMC run            \n",
    "if initializeWithOld:\n",
    "    p0_obj = dh.reload_old_fit(path_params, p0_obj, mode)\n",
    "if 'bliss' in mode.lower() and not runMCMC and not initializeWithOld:\n",
    "    # Reload the number of bliss knots used so that you don't need to rerun initilization to remake outputs\n",
    "    Table_par = np.load(path_params)\n",
    "    p0_obj['nBinX'] = Table_par['nBinX'][0]\n",
    "    p0_obj['nBinY'] = Table_par['nBinY'][0]\n",
    "    \n",
    "# makes list of parameters that won't be fitted \n",
    "dparams = helpers.expand_dparams(dparams_input, mode)\n",
    "p0_obj['A']=0.5\n",
    "p0_obj['A_err']=0.5\n",
    "p0_obj['B']=0.01\n",
    "p0_obj['B_err']=0.5\n",
    "p0_obj['q1']=0.028609764174322733\n",
    "p0_obj['q2']=0.05544212401093798\n",
    "p0_obj['nBinX']=84\n",
    "p0_obj['nBinY']=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the guessed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0, p0_labels, p0_fancyLabels = helpers.get_p0(dparams, p0_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup detector, astrophysical, and full-signal functions and prepare priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the astrophysical function\n",
    "astro_func, astro_labels = freeze.make_lambdafunc(astro_models.ideal_lightcurve, p0_labels,\n",
    "                                                  dparams, p0_obj, debug=debug)\n",
    "astro_inputs = time\n",
    "astro_inputs_full = time_full\n",
    "\n",
    "# Compute an initial guess for the astro model\n",
    "astro_guess = astro_func(astro_inputs, **dict([[label, p0[i]] for i, label in enumerate(p0_labels)\n",
    "                                               if label in astro_labels]))\n",
    "\n",
    "# Get the function that checks whether the lightcurve is positive\n",
    "positivity_func, positivity_labels = freeze.make_lambdafunc(astro_models.check_phase, p0_labels,\n",
    "                                                            np.append(dparams, 'checkPhasePhis'),\n",
    "                                                            p0_obj, debug=debug)\n",
    "\n",
    "# Get all of the detector functions used and freeze any requested parameters\n",
    "detec_funcs = []\n",
    "# Get the names of the fitted parameters for each function\n",
    "detec_labels = []\n",
    "# Get the inputs needed for each detector function\n",
    "detec_inputs = []\n",
    "detec_inputs_full = []\n",
    "if 'poly' in mode.lower():\n",
    "    func = detec_models.detec_model_poly\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([xdata, ydata, mode])\n",
    "    detec_inputs_full.append([xdata_full, ydata_full, mode])\n",
    "if 'pld' in mode.lower():\n",
    "    func = detec_models.detec_model_PLD\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([Pnorm, mode])\n",
    "    detec_inputs_full.append([Pnorm_full, mode])\n",
    "if 'bliss' in mode.lower():\n",
    "    func = detec_models.detec_model_bliss\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(bliss.precompute(flux, xdata, ydata, p0_obj['nBinX'], p0_obj['nBinY']))\n",
    "    detec_inputs_full.append(bliss.precompute(flux_full, xdata_full, ydata_full,\n",
    "                                              p0_obj['nBinX'], p0_obj['nBinY']))\n",
    "if 'gp' in mode.lower():\n",
    "    func = detec_models.detec_model_GP\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([flux, xdata, ydata, True])\n",
    "    detec_inputs_full.append([flux_full, xdata_full, ydata_full, True])\n",
    "if 'hside' in mode.lower():\n",
    "    for i, brk in enumerate(breaks):\n",
    "        # Set the break points for the heaviside function\n",
    "        p0_obj[f's{i}break'] = brk\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "    for i in range(len(breaks), 5):\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}']\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "        dparams = np.append(dparams, [f's{i}'])\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "    func = detec_models.hside\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'tslope' in mode.lower():\n",
    "    func = detec_models.tslope\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'psfw' in mode.lower():\n",
    "    func = detec_models.detec_model_PSFW\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([psfxw, psfyw])\n",
    "    detec_inputs_full.append([psfxw_full, psfyw_full])\n",
    "    \n",
    "if len(detec_funcs)==0:\n",
    "    raise NotImplementedError(f'mode=\\'{mode}\\' is not implemented.')\n",
    "\n",
    "# Put gparams and uparams in the right order and remove any that aren't being fitted\n",
    "gparams = np.array([parm for parm in p0_labels if parm in gparams])\n",
    "uparams_unsorted = np.copy(uparams)\n",
    "uparams = np.array([parm for parm in p0_labels if parm in uparams])\n",
    "uparams_limits = np.array([uparams_limits[np.where(uparams_unsorted==uparams[i])[0][0]]\n",
    "                           for i in range(len(uparams))])\n",
    "\n",
    "gpriorInds = np.array([np.where(p0_labels==gpar)[0][0] for gpar in gparams])\n",
    "upriorInds = np.array([np.where(p0_labels==upar)[0][0] for upar in uparams if upar in p0_labels])\n",
    "if 'gp' in mode.lower():\n",
    "    gammaInd = np.where(p0_labels=='gpAmp')[0][0]\n",
    "else:\n",
    "    gammaInd = None\n",
    "\n",
    "# set up Gaussian priors\n",
    "priors, errs = dh.setup_gpriors(gparams, p0_obj)\n",
    "    \n",
    "# Get the full-signal function that models the astrophysical and detector signals\n",
    "signal_func = detec_models.signal\n",
    "signal_inputs = [p0_labels, astro_func, astro_labels, astro_inputs, detec_funcs, detec_labels, detec_inputs]\n",
    "signal_inputs_full = [p0_labels, astro_func, astro_labels, astro_inputs_full,\n",
    "                      detec_funcs, detec_labels, detec_inputs_full]\n",
    "\n",
    "lnprob_inputs = [flux, mode, p0_labels, signal_func, signal_inputs,\n",
    "                 gpriorInds, priors, errs, upriorInds, uparams_limits, gammaInd,\n",
    "                 positivity_func, positivity_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run initial optimization on detector parameters\n",
    "\n",
    "### Run several gradient descents, short MCMCs, and then gradient descents to allow full burn-in\n",
    "\n",
    "#### Feel free to use your own maximum likelihood method - here we just offer a simple method that should often work. The objective of this step is just to start the final MCMC in a reasonable region of parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:04<00:00,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ln-likelihood!\n",
      "ln-likelihood: 46875.76\n",
      "Optimizing BLISS Bin Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 43/43 [1:37:49<00:00, 136.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard defaulting to blissNBin = [84, 64]\n",
      "Running iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [01:03<00:00,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running first mini burn-ins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:13<00:00,  7.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:15<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:11<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:16<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:19<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:19<00:00,  7.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:04<00:00,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:19<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:20<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [02:16<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.444\n",
      "Running final iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 10/10 [00:58<00:00,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ln-likelihood!\n",
      "ln-likelihood: 46883.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if runMCMC and not initializeWithOld:\n",
    "    \n",
    "    p0 = dh.burnIn(p0, p0_labels, mode, astro_func, astro_labels, astro_inputs, astro_inputs_full, \n",
    "                   signal_func, signal_inputs, signal_inputs_full, lnprob_inputs,\n",
    "                   gparams, gpriorInds, priors, errs, time, flux, breaks,\n",
    "                   bestfitNbin, ncpu, savepath, showPlot=True, nIterScipy=nIterScipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 64\n"
     ]
    }
   ],
   "source": [
    "print(p0_obj['nBinX'], p0_obj['nBinY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MCMC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 6000/6000 [2:08:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acceptance fraction: 0.459\n"
     ]
    }
   ],
   "source": [
    "ndim, nwalkers = len(p0), 150\n",
    "\n",
    "if runMCMC:\n",
    "    # get scattered starting points in parameter space\n",
    "    # MUST have the initial spread such that every walker passes the lnprior functions\n",
    "    p0_rel_errs = 1e-6*np.ones_like(p0)\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "    pos0 = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                     for i in range(nwalkers)])\n",
    "\n",
    "    # Make sure that all starting positions pass the lnpriors, fix them if they don't\n",
    "    priorlnls = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs)) for p_tmp in pos0])\n",
    "    iters = 10\n",
    "    while np.any(priorlnls) and iters>0:\n",
    "        p0_rel_errs /= 1.5\n",
    "        pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))\n",
    "                                      +p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                                    for i in range(np.sum(priorlnls))])\n",
    "        priorlnls[priorlnls] = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs))\n",
    "                                         for p_tmp in pos0[priorlnls]])\n",
    "        iters -= 1\n",
    "    if iters==0 and np.any(priorlnls):\n",
    "        print('Warning: Some of the initial values still fail the lnprior!')\n",
    "        print('The following MCMC will likely not work')\n",
    "\n",
    "    # Run the MCMC\n",
    "    print('Running MCMC')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, helpers.lnprob, args=lnprob_inputs,\n",
    "                                            a = 2, pool=pool)\n",
    "            pos2, prob, state = sampler.run_mcmc(pos0, int(np.rint((nBurnInSteps2+nProductionSteps)/nwalkers)),\n",
    "                                                 progress=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))\n",
    "    \n",
    "    # Show the evolution of MCMC walkers\n",
    "    burnInChain = sampler.chain[:,:int(np.rint((nBurnInSteps2)/nwalkers)),:]\n",
    "    fname = savepath+'MCMC_burninWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(burnInChain, p0_fancyLabels, 10, fname, showPlot=True)\n",
    "    \n",
    "    # Get only the production steps\n",
    "    lnprobchain = sampler.get_log_prob(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "    chain = sampler.get_chain(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "\n",
    "    #Saving MCMC Results\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    pathposit = savepath + 'samplerposi_'+mode+'.npy'\n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    np.save(pathchain, chain)\n",
    "    np.save(pathlnlchain, lnprobchain)\n",
    "    np.save(pathposit, pos2)\n",
    "    np.save(pathlnpro, prob)   \n",
    "    \n",
    "else:\n",
    "\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    chain = np.load(pathchain)\n",
    "    lnprobchain = np.load(pathlnlchain)\n",
    "    \n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    if os.path.exists(pathlnpro):\n",
    "        lnprobability = np.load(pathlnpro)\n",
    "\n",
    "samples = chain.reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results from MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC result:\n",
      "\n",
      "      rp = 0.01623273744169797  +0.000831274325530082  -0.0008441398554282532\n",
      "      fp = 0.0001759436988540841  +2.528186569971408e-05  -2.4808599834371867e-05\n",
      "       A = 0.868180688586959  +0.1860509263142972  -0.15077134199710218\n",
      "       B = 0.2121052717224649  +0.13605782267733874  -0.13001070821110555\n",
      "      d1 = 1.0004551562465456  +0.00016669747063491336  -0.00016792171359658603\n",
      "      d2 = -0.0005233020254722777  +0.0001865955184015165  -0.00019053073015094476\n",
      "      d3 = -5.5268616579632755e-05  +0.00016924997755182535  -0.00016911981718522196\n",
      "    sigF = 0.00044307926989421394  +3.6686073210752315e-06  -3.610152154582202e-06\n",
      "Phase Semi-amplitude = 0.0001722175292784093  +3.3975193631858756e-05  -2.7618319069600336e-05 \n",
      "  Offset = -15.675675675675652  +7.567567567567551  -7.207207207207219 degrees east\n",
      " T Day:  = 3439.203727844957  +455.56507358400086  -396.469548654356\n",
      "T Night:  = -1185.8965092199908  +426.4986010660457  -485.33207358389586\n",
      "For T_{*,b} = 4920.0\n",
      "\n",
      "Binned data:\n",
      "    chi2 = 7411.38594552298\n",
      "    chi2datum = 0.9961540249358845\n",
      "    Likelihood = 46907.312616641335\n",
      "    Evidence = 46871.654112130025\n",
      "    BIC = -93743.30822426005\n",
      "\n",
      "Unbinned data:\n",
      "    chi2 = 2184543.4494868326\n",
      "    chi2datum = 0.4587834865353731\n",
      "    Likelihood = 15916588.41821146\n",
      "    Evidence = 15898260.113800876\n",
      "    BIC = -31796520.22760175\n"
     ]
    }
   ],
   "source": [
    "p0_mcmc, MCMC_Results, residuals = dh.print_MCMC_results(flux, flux_full, chain, lnprobchain, mode, channel,\n",
    "                                                         signal_func, signal_inputs, signal_inputs_full,\n",
    "                                                         p0_labels, p0_obj, astro_func, astro_inputs,\n",
    "                                                         astro_inputs_full, astro_labels, usebestfit, savepath,\n",
    "                                                         sigF_photon_ppm, nFrames, secondOrderOffset,\n",
    "                                                         compFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot showing the evolution of the astro parameters\n",
    "ind_a = len(astro_labels) # index where the astro params\n",
    "labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "fname = savepath+'MCMC_astroWalkers_'+mode+'.pdf'\n",
    "make_plots.walk_style(chain[:,:,:ind_a], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a plot showing the evolution of the detector parameters\n",
    "if 'bliss' not in mode.lower() or r'$\\sigma_F$' in p0_fancyLabels:\n",
    "    labels = p0_fancyLabels[np.logical_not(np.in1d(p0_labels, astro_labels))]\n",
    "    fname = savepath+'MCMC_detecWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(chain[:,:,ind_a:], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a corner plot for the astro parameters\n",
    "if runMCMC:\n",
    "    labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "    fig = corner.corner(samples[:,:ind_a], labels=labels, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                        plot_datapoints=True, title_kwargs={\"fontsize\": 12})\n",
    "    plotname = savepath + 'MCMC_corner_'+mode+'.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out the RAM\n",
    "samples = None\n",
    "sampler = None\n",
    "chain = None\n",
    "lnprobchain = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the final model (best-fit parameters if usebestfit==True, otherwise median of MCMC chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "astroModel = astro_func(astro_inputs, **dict([[label, p0_mcmc[i]] for i, label in enumerate(p0_labels)\n",
    "                                              if label in astro_labels]))\n",
    "signalModel = signal_func(p0_mcmc, *signal_inputs)\n",
    "detecModel = signalModel/astroModel\n",
    "\n",
    "make_plots.plot_model(time, flux, astroModel, detecModel, breaks, savepath, 'Bestfit_'+mode+'.pdf',\n",
    "                      nbin=bestfitNbin, showPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over Ingress (1.6 min):\n",
      "Expected Noise (ppm)\tObserved Noise (ppm)\n",
      "312.7432076424888\t336.0817220299333\n",
      "Observed/Expected\n",
      "1.0746251679241068\n",
      "\n",
      "Over Transit/Eclipse (95.9 min):\n",
      "Expected Noise (ppm)\tObserved Noise (ppm)\n",
      "34.41068051237817\t78.11935815910054\n",
      "Observed/Expected\n",
      "2.2702067205848935\n"
     ]
    }
   ],
   "source": [
    "#WARNING: these durations assume circular orbits!!!\n",
    "intTime = (time[1]-time[0])\n",
    "ingrDuration = helpers.getIngressDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "occDuration = helpers.getOccultationDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "\n",
    "minBins = 5\n",
    "\n",
    "make_plots.plot_rednoise(residuals, minBins, ingrDuration, occDuration, intTime,\n",
    "                         mode, savepath, savetxt=True, showPlot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for residual correlations after fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pld' not in mode.lower():\n",
    "    make_plots.look_for_residual_correlations(time, flux, xdata, ydata, psfxw, psfyw, residuals,\n",
    "                                              p0_mcmc, p0_labels, p0_obj, mode, savepath, showPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
