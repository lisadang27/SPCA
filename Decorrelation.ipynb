{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import inspect\n",
    "\n",
    "# SPCA libraries\n",
    "from SPCA import helpers, astro_models, make_plots, make_plots_custom, detec_models, bliss, freeze\n",
    "from SPCA import Decorrelation_helper as dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter in parameters that will define how the rest of the code will run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet = '55cnc_Nobug'\n",
    "channel = 'ch2'\n",
    "mode = 'BLISS_v1,psfw'\n",
    "rootpath = '/Users/samsonmercier/Desktop/Research'\n",
    "\n",
    "# parameters you do not wish to fit\n",
    "dparams_input = ['q1', 'q2', 'inc', 'ecosw', 'esinw', 'gpLx', 'gpLy', 't0', 'per', 'a']\n",
    "\n",
    "# parameters you want to place a gaussian prior on\n",
    "gparams = ['A', 'B']\n",
    "\n",
    "# parameters you want to place a uniform prior on\n",
    "uparams = ['rp', 'fp', 'sigF']\n",
    "uparams_limits = [[0,1], [0,1], [0,1]]\n",
    "\n",
    "binnedPhotometry = True                  # Whether or not to use the binned photometry\n",
    "oldPhotometry = False                    # Whether photometry was computed before May 1, 2020 when flux conversion was patched\n",
    "ncpu = 1                                 # The number of cpu threads to be used when running MCMC\n",
    "runMCMC = True                           # whether to run MCMC or just load-in past results\n",
    "nIterScipy = 10                          # Number of iterative scipy runs used to locate best-fit before starting MCMCs\n",
    "nBurnInSteps2 = 7.5e5                    # number of steps to use for the second mcmc burn-in\n",
    "nProductionSteps = 1.5e5                 # number of steps to use with mcmc production run\n",
    "usebestfit = True                        # used best-fit instead of median of chain\n",
    "secondOrderOffset = True                 # should you use the second order sinusoid terms when calculating offset\n",
    "bestfitNbin = 50                         # the number of binned values to overplot on the bestfit 4-panel figure (use None if you don't want these overplotted)\n",
    "nFrames  = 640                            # number of frames per binned data point\n",
    "initializeWithOld = False                # initial with previous mcmc results using the same method\n",
    "pldIgnoreFrames = True                   # Whether or not to use the PLD photometry that ignored bad frames\n",
    "pldAddStack = False                      # Whether or not to use the PLD photometry that used background correction stacks\n",
    "debug = False                            # True if user wants details about the lambda functions created\n",
    "\n",
    "# Adding companion dilution correction factor for CoRoT-2b, WASP-12b, and WASP-103b\n",
    "if planet=='CoRoT-2b':\n",
    "    compFactor = 1+0.2046\n",
    "elif planet=='WASP-12b':\n",
    "    compFactor = 1+0.09976\n",
    "elif planet=='WASP-12b_old':\n",
    "    compFactor = 1+0.09085\n",
    "elif planet=='WASP-103b':\n",
    "    compFactor = 1+0.1234\n",
    "else:\n",
    "    compFactor = 1\n",
    "\n",
    "# non-zero if you want to remove some initial data points\n",
    "cut_tmp = 0\n",
    "\n",
    "foldername = rootpath + '/55cnc_Nobug/4umExactCircular2_2_movingCentroid/'\n",
    "foldername_psf = rootpath + '/55cnc_Nobug/4umExactCircular2_2_movingCentroid/'\n",
    "filename = 'ch2_datacube_binned_AORs4807.dat'\n",
    "filename_full = 'ch2_datacube_full_AORs4807.dat'\n",
    "savepath = foldername + mode + '/'\n",
    "#path_params = \n",
    "AOR_snip = []\n",
    "aors = []\n",
    "breaks = []\n",
    "ignoreFrames = []\n",
    "cutFirstAOR = []\n",
    "cut=cut_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Everything below can be run without interfering with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rootpath[-1]!='/':\n",
    "    rootpath += '/'\n",
    "if not binnedPhotometry:\n",
    "    nFrames = 1\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Figure out where data is located\n",
    "if 'pldaper' in mode.lower():\n",
    "    # Get separately aperture data for when running PLDAper, and decide if ignoreFrame from aperture photometry\n",
    "    foldername_aper, ignoreFrames = np.array(dh.findPhotometry(rootpath, planet, channel, '_v1'))[[0,-1]]\n",
    "    if len(ignoreFrames)==0:\n",
    "        pldIgnoreFrames = False\n",
    "    else:\n",
    "        pldIgnoreFrames = True\n",
    "    foldername_psf = ''\n",
    "else:\n",
    "    foldername_aper = ''\n",
    "\n",
    "if 'psfx' in mode.lower():\n",
    "    foldername_psf = dh.findPhotometry(rootpath, planet, channel, 'PSFX')[0]\n",
    "else:\n",
    "    foldername_psf = ''\n",
    "\n",
    "(foldername, filename, filename_full, savepath,\n",
    "path_params, AOR_snip, aors, breaks, ignoreFrames) = dh.findPhotometry(rootpath, planet, channel,\n",
    "                                                                       mode, pldIgnoreFrames, pldAddStack)\n",
    "\n",
    "with open(rootpath+planet+'/analysis/'+channel+'/cutFirstAOR.txt', 'r') as file:\n",
    "    cutFirstAOR = file.readline().strip()=='True'\n",
    "\n",
    "# For datasets where the first AOR is peak-up data\n",
    "\n",
    "if cutFirstAOR:\n",
    "    rawfiles = np.sort(os.listdir(rootpath+planet+'/data/'+channel+'/'+aors[0]+'/'+channel+'/bcd/'))\n",
    "    rawfiles  = [rawfile for rawfile in rawfiles if '_bcd.fits' in rawfile]\n",
    "    cut = cut_tmp+len(rawfiles)\n",
    "else:\n",
    "    cut = cut_tmp\n",
    "'''\n",
    "# loading full data set for BIC calculation afterwards\n",
    "if 'pld' in mode.lower():\n",
    "    # get data from unbinned photometry for chi2 on unbinned data calculation later\n",
    "    Pnorm_full, flux_full, time_full = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                             foldername_aper=foldername_aper,\n",
    "                                                             cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    if binnedPhotometry:\n",
    "        Pnorm_0, flux0, time0 = helpers.get_data(foldername, filename, mode,\n",
    "                                                 foldername_aper=foldername_aper)\n",
    "        Pnorm, flux, time = helpers.get_data(foldername, filename, mode,\n",
    "                                             foldername_aper=foldername_aper, cut=cut)\n",
    "    else:\n",
    "        Pnorm, flux, time = Pnorm_full, flux_full, time_full\n",
    "        Pnorm0, flux0, time0 = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                     foldername_aper=foldername_aper,\n",
    "                                                     nFrames=nFrames, ignore=ignoreFrames)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm_full.shape[0]-1))\n",
    "    pca.fit(Pnorm_full.T)\n",
    "    Pnorm_full = pca.transform(Pnorm_full.T).T\n",
    "    Pnorm_full = np.append(np.ones_like(Pnorm_full[:1]), Pnorm_full, axis=0)\n",
    "    \n",
    "    pca = PCA(n_components=int(Pnorm.shape[0]-1))\n",
    "    pca.fit(Pnorm.T)\n",
    "    Pnorm = pca.transform(Pnorm.T).T\n",
    "    Pnorm = np.append(np.ones_like(Pnorm[:1]), Pnorm, axis=0)\n",
    "    \n",
    "    if not oldPhotometry:\n",
    "        if 'pldaper' in mode.lower():\n",
    "            path_temp = foldername_aper\n",
    "        else:\n",
    "            path_temp = foldername\n",
    "        if binnedPhotometry:\n",
    "            path_temp += filename\n",
    "        else:\n",
    "            path_temp += filename_full\n",
    "        sigF_photon_ppm = dh.get_photon_limit(path_temp, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    # FIX: Add an initial PLD plot\n",
    "else:\n",
    "    # get data from photometry\n",
    "    (flux_full, time_full, xdata_full, ydata_full,\n",
    "     psfxw_full, psfyw_full) = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                     foldername_psf=foldername_psf,\n",
    "                                                     cut=cut, nFrames=nFrames, ignore=ignoreFrames)\n",
    "    # Get Data we'll analyze\n",
    "    if binnedPhotometry:\n",
    "        flux0, time0, xdata0, ydata0, psfxw0, psfyw0 = helpers.get_data(foldername, filename, mode,\n",
    "                                                                          foldername_psf=foldername_psf)\n",
    "        flux, time, xdata, ydata, psfxw, psfyw = helpers.get_data(foldername, filename, mode,\n",
    "                                                                    foldername_psf=foldername_psf, cut=cut)\n",
    "        \n",
    "        if not oldPhotometry:\n",
    "            sigF_photon_ppm = dh.get_photon_limit(foldername+filename, mode, nFrames, ignoreFrames)\n",
    "    else:\n",
    "        flux, time, xdata, ydata, psfxw, psfyw = (flux_full, time_full, xdata_full, ydata_full,\n",
    "                                                  psfxw_full, psfyw_full)\n",
    "        flux0, time0, xdata0, ydata0, psfxw0, psfyw0 = helpers.get_full_data(foldername, filename_full, mode,\n",
    "                                                                             foldername_psf=foldername_psf,\n",
    "                                                                             cut=cut, nFrames=nFrames,\n",
    "                                                                             ignore=ignoreFrames)\n",
    "        \n",
    "        if not oldPhotometry:\n",
    "            sigF_photon_ppm = dh.get_photon_limit(foldername+filename_full, mode, nFrames, ignoreFrames)\n",
    "    \n",
    "    ## FIX: peritime doesn't get made\n",
    "    if True:#'ecosw' in dparams_input and 'esinw' in dparams_input:\n",
    "        # make photometry plots\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   showPlot=True)\n",
    "    else:\n",
    "        # plot raw data\n",
    "        make_plots.plot_photometry(time0, flux0, xdata0, ydata0, psfxw0, psfyw0, \n",
    "                                   time, flux, xdata, ydata, psfxw, psfyw, breaks, savepath,\n",
    "                                   peritime, showPlot=True)\n",
    "\n",
    "# Calculate the photon noise limit\n",
    "if oldPhotometry:\n",
    "    # Fix the old, unhelpful units to electrons to compute photon noise limit\n",
    "    if binnedPhotometry:\n",
    "        sigF_photon_ppm = dh.get_photon_limit_oldData(rootpath, foldername+filename_full, foldername_aper+filename_full,\n",
    "                                                      planet, channel, mode, aors, nFrames, ignoreFrames)\n",
    "    else:\n",
    "        sigF_photon_ppm = dh.get_photon_limit_oldData(rootpath, foldername+filename, foldername_aper+filename,\n",
    "                                                      planet, channel, mode, aors, nFrames, ignoreFrames)\n",
    "        \n",
    "sigF_photon_ppm *= compFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load archival/custom data and prepare some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the most recent exoplanet archive data, and select the best constrained value for each parameter\n",
    "'''dh.downloadExoplanetArchive()\n",
    "if planet!='WASP-18b':\n",
    "    p0_obj = dh.loadArchivalData(rootpath, planet, channel)'''\n",
    "\n",
    "## If you would rather load your own data (e.g. your planet isn't in the exoplanet archive),\n",
    "## you can use the function below. The error parameters are optional inputs, but are required if you want\n",
    "## to put a prior on a parameter.\n",
    "if planet=='WASP-18b':\n",
    "    # The combination of parameters loaded for WASP-18b are not consistent with each other\n",
    "    p0_obj = dh.loadCustomData(rootpath, planet, channel, 0.09716, 3.562, 0.9414526, 2458375.169883,\n",
    "                               84.88, 0.0091, 269, 6431, 4.47, 0.11,\n",
    "                               0.00014, 0.022, 0.000026, 0.0000016, 0.33, 0.00200, 3, 48)\n",
    "else:\n",
    "    p0_obj = dh.loadCustomData(rootpath, planet, channel, 0.0182, 3.52, 0.7365474, 2457063.2096, 83.59, 0, 0, 5172, 4.43, 0.35,\n",
    "                              0.0002, 0.01, 0.0005, 0.0000014, 0.46, 0, 0, 18)\n",
    "# p0_obj = loadCustomData(rootpath, planet, channel, rp, a, per, t0, inc, e, argp, Tstar, logg, feh,\n",
    "#                         rp_err, a_err, t0_err, per_err, inc_err, e_err, argp_err, Tstar_err)\n",
    "\n",
    "# if you want to use the best fit params from a previous MCMC run            \n",
    "if initializeWithOld:\n",
    "    p0_obj = dh.reload_old_fit(path_params, p0_obj, mode)\n",
    "if 'bliss' in mode.lower() and not runMCMC and not initializeWithOld:\n",
    "    # Reload the number of bliss knots used so that you don't need to rerun initilization to remake outputs\n",
    "    Table_par = np.load(path_params)\n",
    "    p0_obj['nBinX'] = Table_par['nBinX'][0]\n",
    "    p0_obj['nBinY'] = Table_par['nBinY'][0]\n",
    "    \n",
    "# makes list of parameters that won't be fitted \n",
    "dparams = helpers.expand_dparams(dparams_input, mode)\n",
    "p0_obj['A']=0.5\n",
    "p0_obj['A_err']=0.05\n",
    "p0_obj['B']=0.01\n",
    "p0_obj['B_err']=0.05\n",
    "p0_obj['q1']=0.028609764174322733\n",
    "p0_obj['q2']=0.05544212401093798\n",
    "p0_obj['nBinX']=84\n",
    "p0_obj['nBinY']=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the guessed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0, p0_labels, p0_fancyLabels = helpers.get_p0(dparams, p0_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rp', 'fp', 'A', 'B', 'd1', 'd2', 'd3', 'sigF'], dtype='<U4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup detector, astrophysical, and full-signal functions and prepare priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the astrophysical function\n",
    "astro_func, astro_labels = freeze.make_lambdafunc(astro_models.ideal_lightcurve, p0_labels,\n",
    "                                                  dparams, p0_obj, debug=debug)\n",
    "astro_inputs = time\n",
    "astro_inputs_full = time_full\n",
    "\n",
    "# Compute an initial guess for the astro model\n",
    "astro_guess = astro_func(astro_inputs, **dict([[label, p0[i]] for i, label in enumerate(p0_labels)\n",
    "                                               if label in astro_labels]))\n",
    "\n",
    "# Get the function that checks whether the lightcurve is positive\n",
    "positivity_func, positivity_labels = freeze.make_lambdafunc(astro_models.check_phase, p0_labels,\n",
    "                                                            np.append(dparams, 'checkPhasePhis'),\n",
    "                                                            p0_obj, debug=debug)\n",
    "\n",
    "# Get all of the detector functions used and freeze any requested parameters\n",
    "detec_funcs = []\n",
    "# Get the names of the fitted parameters for each function\n",
    "detec_labels = []\n",
    "# Get the inputs needed for each detector function\n",
    "detec_inputs = []\n",
    "detec_inputs_full = []\n",
    "if 'poly' in mode.lower():\n",
    "    func = detec_models.detec_model_poly\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([xdata, ydata, mode])\n",
    "    detec_inputs_full.append([xdata_full, ydata_full, mode])\n",
    "if 'pld' in mode.lower():\n",
    "    func = detec_models.detec_model_PLD\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([Pnorm, mode])\n",
    "    detec_inputs_full.append([Pnorm_full, mode])\n",
    "if 'bliss' in mode.lower():\n",
    "    func = detec_models.detec_model_bliss\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(bliss.precompute(flux, xdata, ydata, p0_obj['nBinX'], p0_obj['nBinY']))\n",
    "    detec_inputs_full.append(bliss.precompute(flux_full, xdata_full, ydata_full,\n",
    "                                              p0_obj['nBinX'], p0_obj['nBinY']))\n",
    "if 'gp' in mode.lower():\n",
    "    func = detec_models.detec_model_GP\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([flux, xdata, ydata, True])\n",
    "    detec_inputs_full.append([flux_full, xdata_full, ydata_full, True])\n",
    "if 'hside' in mode.lower():\n",
    "    for i, brk in enumerate(breaks):\n",
    "        # Set the break points for the heaviside function\n",
    "        p0_obj[f's{i}break'] = brk\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "    for i in range(len(breaks), 5):\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}']\n",
    "        p0_fancyLabels = p0_fancyLabels[p0_labels!=f's{i}break']\n",
    "        p0_labels = p0_labels[p0_labels!=f's{i}break']\n",
    "        dparams = np.append(dparams, [f's{i}'])\n",
    "        dparams = np.append(dparams, [f's{i}break'])\n",
    "    func = detec_models.hside\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'tslope' in mode.lower():\n",
    "    func = detec_models.tslope\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append(time)\n",
    "    detec_inputs_full.append(time_full)\n",
    "if 'psfw' in mode.lower():\n",
    "    func = detec_models.detec_model_PSFW\n",
    "    func, labels = freeze.make_lambdafunc(func, p0_labels, dparams, p0_obj, debug=debug)\n",
    "    detec_funcs.append(func)\n",
    "    detec_labels.append(labels)\n",
    "    detec_inputs.append([psfxw, psfyw])\n",
    "    detec_inputs_full.append([psfxw_full, psfyw_full])\n",
    "    \n",
    "if len(detec_funcs)==0:\n",
    "    raise NotImplementedError(f'mode=\\'{mode}\\' is not implemented.')\n",
    "\n",
    "# Put gparams and uparams in the right order and remove any that aren't being fitted\n",
    "gparams = np.array([parm for parm in p0_labels if parm in gparams])\n",
    "uparams_unsorted = np.copy(uparams)\n",
    "uparams = np.array([parm for parm in p0_labels if parm in uparams])\n",
    "uparams_limits = np.array([uparams_limits[np.where(uparams_unsorted==uparams[i])[0][0]]\n",
    "                           for i in range(len(uparams))])\n",
    "\n",
    "gpriorInds = np.array([np.where(p0_labels==gpar)[0][0] for gpar in gparams])\n",
    "upriorInds = np.array([np.where(p0_labels==upar)[0][0] for upar in uparams if upar in p0_labels])\n",
    "if 'gp' in mode.lower():\n",
    "    gammaInd = np.where(p0_labels=='gpAmp')[0][0]\n",
    "else:\n",
    "    gammaInd = None\n",
    "\n",
    "# set up Gaussian priors\n",
    "priors, errs = dh.setup_gpriors(gparams, p0_obj)\n",
    "    \n",
    "# Get the full-signal function that models the astrophysical and detector signals\n",
    "signal_func = detec_models.signal\n",
    "signal_inputs = [p0_labels, astro_func, astro_labels, astro_inputs, detec_funcs, detec_labels, detec_inputs]\n",
    "signal_inputs_full = [p0_labels, astro_func, astro_labels, astro_inputs_full,\n",
    "                      detec_funcs, detec_labels, detec_inputs_full]\n",
    "\n",
    "lnprob_inputs = [flux, mode, p0_labels, signal_func, signal_inputs,\n",
    "                 gpriorInds, priors, errs, upriorInds, uparams_limits, gammaInd,\n",
    "                 positivity_func, positivity_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run initial optimization on detector parameters\n",
    "\n",
    "### Run several gradient descents, short MCMCs, and then gradient descents to allow full burn-in\n",
    "\n",
    "#### Feel free to use your own maximum likelihood method - here we just offer a simple method that should often work. The objective of this step is just to start the final MCMC in a reasonable region of parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ln-likelihood!\n",
      "ln-likelihood: 46797.10\n",
      "Optimizing BLISS Bin Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 43/43 [19:32<00:00, 27.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using blissNBin = [84, 64]\n",
      "Running iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:14<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ln-likelihood!\n",
      "ln-likelihood: 46781.67\n",
      "Running first mini burn-ins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:29<00:00, 35.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:29<00:00, 35.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:30<00:00, 35.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████| 1062/1062 [00:29<00:00, 35.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean burn-in acceptance fraction: 0.437\n",
      "Running final iterative scipy.optimize on all parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 10/10 [00:08<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ln-likelihood!\n",
      "ln-likelihood: 46872.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if runMCMC and not initializeWithOld:\n",
    "    \n",
    "    p0 = dh.burnIn(p0, p0_labels, mode, astro_func, astro_labels, astro_inputs, astro_inputs_full, \n",
    "                   signal_func, signal_inputs, signal_inputs_full, lnprob_inputs,\n",
    "                   gparams, gpriorInds, priors, errs, time, flux, breaks,\n",
    "                   bestfitNbin, ncpu, savepath, showPlot=True, nIterScipy=nIterScipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 64\n"
     ]
    }
   ],
   "source": [
    "print(p0_obj['nBinX'], p0_obj['nBinY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some of the initial values still fail the lnprior!\n",
      "The following MCMC will likely not work\n",
      "Running MCMC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6000/6000 [14:01<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acceptance fraction: 0.430\n"
     ]
    }
   ],
   "source": [
    "ndim, nwalkers = len(p0), 150\n",
    "\n",
    "if runMCMC:\n",
    "    # get scattered starting points in parameter space\n",
    "    # MUST have the initial spread such that every walker passes the lnprior functions\n",
    "    p0_rel_errs = 1e-6*np.ones_like(p0)\n",
    "    gpriorInds = [np.where(p0_labels==gpar)[0][0] for gpar in gparams]\n",
    "    p0_rel_errs[gpriorInds] = np.array(errs)/np.array(priors)\n",
    "    pos0 = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))+p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                     for i in range(nwalkers)])\n",
    "\n",
    "    # Make sure that all starting positions pass the lnpriors, fix them if they don't\n",
    "    priorlnls = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs)) for p_tmp in pos0])\n",
    "    iters = 10\n",
    "    while np.any(priorlnls) and iters>0:\n",
    "        p0_rel_errs /= 1.5\n",
    "        pos0[priorlnls] = np.array([p0*(1+p0_rel_errs*np.random.randn(ndim))\n",
    "                                      +p0_rel_errs/10.*np.abs(np.random.randn(ndim))\n",
    "                                    for i in range(np.sum(priorlnls))])\n",
    "        priorlnls[priorlnls] = np.array([np.isinf(helpers.lnprob(p_tmp, *lnprob_inputs))\n",
    "                                         for p_tmp in pos0[priorlnls]])\n",
    "        iters -= 1\n",
    "    if iters==0 and np.any(priorlnls):\n",
    "        print('Warning: Some of the initial values still fail the lnprior!')\n",
    "        print('The following MCMC will likely not work')\n",
    "\n",
    "    # Run the MCMC\n",
    "    print('Running MCMC')\n",
    "    with threadpool_limits(limits=1, user_api='blas'):\n",
    "        with Pool(ncpu) as pool:\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, helpers.lnprob, args=lnprob_inputs,\n",
    "                                            a = 2, pool=pool)\n",
    "            pos2, prob, state = sampler.run_mcmc(pos0, int(np.rint((nBurnInSteps2+nProductionSteps)/nwalkers)),\n",
    "                                                 progress=True)\n",
    "    print(\"Mean acceptance fraction: {0:.3f}\".format(np.mean(sampler.acceptance_fraction)))\n",
    "    \n",
    "    # Show the evolution of MCMC walkers\n",
    "    burnInChain = sampler.chain[:,:int(np.rint((nBurnInSteps2)/nwalkers)),:]\n",
    "    fname = savepath+'MCMC_burninWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(burnInChain, p0_fancyLabels, 10, fname, showPlot=True)\n",
    "    \n",
    "    # Get only the production steps\n",
    "    lnprobchain = sampler.get_log_prob(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "    chain = sampler.get_chain(discard=int(np.rint((nBurnInSteps2)/nwalkers))).swapaxes(0,1)\n",
    "\n",
    "    #Saving MCMC Results\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    pathposit = savepath + 'samplerposi_'+mode+'.npy'\n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    np.save(pathchain, chain)\n",
    "    np.save(pathlnlchain, lnprobchain)\n",
    "    np.save(pathposit, pos2)\n",
    "    np.save(pathlnpro, prob)   \n",
    "    \n",
    "else:\n",
    "\n",
    "    pathchain = savepath + 'samplerchain_'+mode+'.npy'\n",
    "    pathlnlchain = savepath + 'samplerlnlchain_'+mode+'.npy'\n",
    "    chain = np.load(pathchain)\n",
    "    lnprobchain = np.load(pathlnlchain)\n",
    "    \n",
    "    pathlnpro = savepath + 'samplerlnpr_'+mode+'.npy'\n",
    "    if os.path.exists(pathlnpro):\n",
    "        lnprobability = np.load(pathlnpro)\n",
    "\n",
    "samples = chain.reshape((-1, ndim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output results from MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00018452937709538618\n",
      "MCMC result:\n",
      "\n",
      "      rp = 0.016940736857087035  +0.0007960595455395597  -0.0008200763640359952\n",
      "      fp = 0.00018452937709538618  +2.4945361259832364e-05  -2.4304283154191693e-05\n",
      "       A = 0.4954083899821861  +0.013043514249520716  -0.02396545059850641\n",
      "       B = 0.044545144590594186  +0.042681069002370634  -0.04256719737000779\n",
      "      d1 = 1.0004578047355663  +0.00016116485425921034  -0.00016772399686248995\n",
      "      d2 = -0.000509010771415283  +0.00018610523049063254  -0.00018491198471667794\n",
      "      d3 = -7.79142529453402e-05  +0.00016497648129758203  -0.00016515680215201676\n",
      "    sigF = 0.00044480927768599876  +3.705056633468754e-06  -3.5482759452578824e-06\n",
      "Phase Semi-amplitude = 8.919826458948567e-05  +2.409830803596163e-06  -4.395177541713008e-06 \n",
      "  Offset = -2.7027027027027004  +5.045045045045042  -5.0450450450450415 degrees east\n",
      " T Day:  = 3738.5670404843227  +463.0921439738481  -401.7697476041458\n",
      "T Night:  = 888.9615199195011  +246.10844989161615  -218.20908421682725\n",
      "For T_{*,b} = 4920.0\n",
      "\n",
      "Binned data:\n",
      "    chi2 = 7376.980538267026\n",
      "    chi2datum = 0.9915296422401916\n",
      "    Likelihood = 46895.52232493355\n",
      "    Evidence = 46859.86382042224\n",
      "    BIC = -93719.72764084447\n",
      "\n",
      "Unbinned data:\n",
      "    chi2 = 2167737.370567684\n",
      "    chi2datum = 0.45525398407419443\n",
      "    Likelihood = 15906435.940656144\n",
      "    Evidence = 15888107.63624556\n",
      "    BIC = -31776215.27249112\n"
     ]
    }
   ],
   "source": [
    "p0_mcmc, MCMC_Results, residuals = dh.print_MCMC_results(flux, flux_full, chain, lnprobchain, mode, channel,\n",
    "                                                         signal_func, signal_inputs, signal_inputs_full,\n",
    "                                                         p0_labels, p0_obj, astro_func, astro_inputs,\n",
    "                                                         astro_inputs_full, astro_labels, usebestfit, savepath,\n",
    "                                                         sigF_photon_ppm, nFrames, secondOrderOffset,\n",
    "                                                         compFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot showing the evolution of the astro parameters\n",
    "ind_a = len(astro_labels) # index where the astro params\n",
    "labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "fname = savepath+'MCMC_astroWalkers_'+mode+'.pdf'\n",
    "make_plots.walk_style(chain[:,:,:ind_a], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a plot showing the evolution of the detector parameters\n",
    "if 'bliss' not in mode.lower() or r'$\\sigma_F$' in p0_fancyLabels:\n",
    "    labels = p0_fancyLabels[np.logical_not(np.in1d(p0_labels, astro_labels))]\n",
    "    fname = savepath+'MCMC_detecWalkers_'+mode+'.pdf'\n",
    "    make_plots.walk_style(chain[:,:,ind_a:], labels, 10, fname, showPlot=True)\n",
    "\n",
    "# Make a corner plot for the astro parameters\n",
    "if runMCMC:\n",
    "    labels = p0_fancyLabels[np.in1d(p0_labels, astro_labels)]\n",
    "    fig = corner.corner(samples[:,:ind_a], labels=labels, quantiles=[0.16, 0.5, 0.84], show_titles=True, \n",
    "                        plot_datapoints=True, title_kwargs={\"fontsize\": 12})\n",
    "    plotname = savepath + 'MCMC_corner_'+mode+'.pdf'\n",
    "    fig.savefig(plotname, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out the RAM\n",
    "samples = None\n",
    "sampler = None\n",
    "chain = None\n",
    "lnprobchain = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the final model (best-fit parameters if usebestfit==True, otherwise median of MCMC chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "astroModel = astro_func(astro_inputs, **dict([[label, p0_mcmc[i]] for i, label in enumerate(p0_labels)\n",
    "                                              if label in astro_labels]))\n",
    "signalModel = signal_func(p0_mcmc, *signal_inputs)\n",
    "detecModel = signalModel/astroModel\n",
    "\n",
    "make_plots.plot_model(time, flux, astroModel, detecModel, breaks, savepath, 'Bestfit_'+mode+'.pdf',\n",
    "                      nbin=bestfitNbin, showPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over Ingress (1.6 min):\n",
      "Expected Noise (ppm)\tObserved Noise (ppm)\n",
      "313.23368928529993\t337.2427416748347\n",
      "Observed/Expected\n",
      "1.0766490106613877\n",
      "\n",
      "Over Transit/Eclipse (95.9 min):\n",
      "Expected Noise (ppm)\tObserved Noise (ppm)\n",
      "34.46464749453963\t81.2760205521565\n",
      "Observed/Expected\n",
      "2.358243198774436\n"
     ]
    }
   ],
   "source": [
    "#WARNING: these durations assume circular orbits!!!\n",
    "intTime = (time[1]-time[0])\n",
    "ingrDuration = helpers.getIngressDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "occDuration = helpers.getOccultationDuration(p0_mcmc, p0_labels, p0_obj, intTime)\n",
    "\n",
    "minBins = 5\n",
    "\n",
    "make_plots.plot_rednoise(residuals, minBins, ingrDuration, occDuration, intTime,\n",
    "                         mode, savepath, savetxt=True, showPlot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for residual correlations after fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'pld' not in mode.lower():\n",
    "    make_plots.look_for_residual_correlations(time, flux, xdata, ydata, psfxw, psfyw, residuals,\n",
    "                                              p0_mcmc, p0_labels, p0_obj, mode, savepath, showPlot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
